---
title: "Section 2: Tidy Data"
format: html
editor: visual
---

# Section 2: Tidy Data

## **Tidy Data Overview**

In the **Tidy Data** section, you will learn how to convert data from a raw to a tidy format.

This section is divided into three parts: **Reshaping Data**, **Combining Tables**, and **Web Scraping**. There are comprehension checks at the end of each part.

After completing the **Tidy Data** section, you will be able to:

-   <div>

    -   **Reshape data** using functions from the **tidyr** package, including `gather()`, `spread()`, `separate()`and `unite()`.

    -   Combine information from different tables using **join** functions from the **dplyr** package.

    -   Combine information from different tables using **binding** functions from the **dplyr** package.

    -   Use **set operators** to combine data frames.

    -   Gather data from a website through **web scraping** and use of **CSS selectors**.

    </div>

We encourage you to use R to interactively test out your answers and further your own learning. If you get stuck, we encourage you to search the discussion boards for the answer to your issue or ask us for help!

## 2.1: Reshaping Data

### **Tidy data**

**Key points**

-   In tidy data, each row represents an observation and each column represents a different variable.

-   In wide data, each row includes several observations and one of the variables is stored in the header.

**Code**

```{r, warning=FALSE}
library(tidyverse)
library(dslabs)
data(gapminder)

# create and inspect a tidy data frame
tidy_data <- gapminder %>% 
  filter(country %in% c("South Korea", "Germany")) %>%
  select(country, year, fertility)
head(tidy_data)

# plotting tidy data is simple
tidy_data %>% 
  ggplot(aes(year, fertility, color = country)) +
  geom_point()

# import and inspect example of original Gapminder data in wide format
path <- system.file("extdata", package="dslabs")
filename <- file.path(path,  "fertility-two-countries-example.csv")
wide_data <- read_csv(filename)
select(wide_data, country, `1960`:`1967`)
```

### **Reshaping data: pivot_longer**

**Key points**

-   After importing data, a common next step is to reshape the data into a form useful for the rest of the analysis by tidying it. The **tidyr** package includes several useful functions for tidying data.

-   The `pivot_longer()` function converts wide data into tidy data.

-   The first argument of `pivot_longer()` is the data frame to be reshaped. The second argument specifies the columns containing the values to be moved into a single column.

-   The new column of values is called `value` by default and the column containing the original names of those columns is called `name` by default.

-   The `values_to` and `names_to` arguments can be used to change the default names of these columns.

**Code**

```{r}
# example dataset: fertility data in wide format (from previous video)
library(tidyverse) 
library(dslabs)
path <- system.file("extdata", package="dslabs")
filename <- file.path(path, "fertility-two-countries-example.csv")
wide_data <- read_csv(filename)

# snippet of wide data
wide_data %>% select(country, '1960':'1965')

# move the values in the columns 1960 through 2015 into a single column
wide_data %>% pivot_longer(`1960`:`2015`)

# another way to do this - only country isn't being pivoted
wide_data %>% pivot_longer(-country)

# change the default column names
new_tidy_data <- wide_data %>% 
  pivot_longer(-country, names_to = "year", values_to = "fertility")
head(new_tidy_data)

# compare the class from our original tidy data (year is an integer) and in the new version (year is a character)
class(tidy_data$year)
class(new_tidy_data$year)

# use the names_transform argument to change the class of the year values to numeric
new_tidy_data <- wide_data %>% 
  pivot_longer(-country, names_to = "year", values_to = "fertility", 
               names_transform = list(year=as.numeric))
               
# plot the data as before
new_tidy_data %>% ggplot(aes(year, fertility, color = country)) +
  geom_point()
```

### **Reshaping data: pivot wider**

**Key points**

-   he `pivot_wider()` function converts tidy data into wide data, which can be a useful intermediate step in data tidying.

-   The data frame to be reshaped is the first argument in `pivot_wider()`.

-   The argument `names_from` tells `pivot_wider()` which variable will be used for the column names and the argument `values_from` tells `pivot_wider()` which variable to use to fill in the values.

-   The [tidyr cheat sheet External link](https://github.com/rstudio/cheatsheets/blob/main/tidyr.pdf) is a useful reference for these and other functions.

**Code**

```{r}
# still working with the same data as in the previous video
# convert the tidy data to wide data
new_wide_data <- new_tidy_data %>% 
  pivot_wider(names_from = year, values_from = fertility)
select(new_wide_data, country, `1960`:`1967`)
```

### **Separate**

**Key points**

-   The `separate()` function splits one column into two or more columns at a specified character that separates the variables.

-   The `separate()` function takes three arguments (apart from the data): the name of the column to be separated, the names to be used for the new columns, and the character that separates the variables.

-   When there is an extra separation, you can use `extra = "merge"` to merge the last two variables.

**Code**

```{r}
# import data
path <- system.file("extdata", package = "dslabs")
fname <-  "life-expectancy-and-fertility-two-countries-example.csv"
filename <- file.path(path, fname)
                     
raw_dat <- read_csv(filename)
select(raw_dat, 1:4)

# pivot all columns except country
dat <- raw_dat %>% pivot_longer(-country)
head(dat)
dat$name[1:5]

# separate on underscores
dat %>% separate(name, c("year", "name"), sep = "_")

# separate on underscores (the default), convert years to numeric
dat %>% separate(name, c("year", "name"), convert = TRUE)

# split on all underscores, pad empty cells with NA
dat %>% separate(name, c("year", "name_1", "name_2"), 
                 fill = "right", convert = TRUE)
                 
# split on first underscore but keep life_expectancy merged
dat %>% separate(name, c("year", "name"), sep = "_", 
                 extra = "merge", convert = TRUE)

# separate then create a new column for each variable using pivot_wider
dat %>% separate(name, c("year", "name"), sep = "_", 
                 extra = "merge", convert = TRUE) %>%
  pivot_wider()
```

### Unite

**Key points**

-   The `unite()` function joins two columns into one.

**Code**

```{r}
# using the data from the previous video
# if we had used this non-optimal approach to separate
dat %>% 
  separate(name, c("year", "name_1", "name_2"), 
           fill = "right", convert = TRUE)

# we could unite the second and third columns using unite()
dat %>% 
  separate(name, c("year", "name_1", "name_2"), 
           fill = "right", convert = TRUE) %>%
  unite(variable_name, name_1, name_2, sep="_")
  
# spread the columns
dat %>% 
  separate(name, c("year", "name_1", "name_2"), 
           fill = "right", convert = TRUE) %>%
  unite(name, name_1, name_2, sep="_") %>%
  spread(name, value) %>%
  rename(fertlity = fertility_NA)
```

### **Assessment Part 1: Reshaping Data**

#### Question 1

If you have numerical data in multiple columns, but you want to combine them into one column, which function should you use?

`separate()`

`pivot_wider()`

`pivot_longer()`

`unite()`

#### Question 2

If you have text data in one column, but you want to split it into multiple columns, which function should you use?

`separate()`

`pivot_wider()`

`pivot_longer()`

`unite()`

#### Question 3

A collaborator sends you a file containing data for three years of average race finish times.

```         
      age_group,2015,2016,2017 
      20,3:46,3:22,3:50 
      30,3:50,3:43,4:43 
      40,4:39,3:49,4:51 
      50,4:48,4:59,5:01     
```

Are these data considered "tidy" in R? Why or why not?

Yes. These data are considered "tidy" because each row contains unique observations.

Yes. These data are considered "tidy" because there are no missing data in the data frame.

No. These data are not considered "tidy" because the variable "year" is stored in the header.

No. These data are not considered "tidy" because there are not an equal number of columns and rows.

#### Question 4

Below are four versions of the same dataset. Which one is in a tidy format?

```         
          state      abb region  population total 
          Alabama     AL    South   4779736   135 
          Alaska      AK   West     710231    19 
          Arizona     AZ   West 6392017   232 
          Arkansas    AR  South 2915918   93 
          California  CA   West   37253956  1257 
          Colorado    CO   West 5029196   65         
```

```         
          state   abb region        var  people 
          Alabama  AL  South population 4779736 
          Alabama  AL  South      total     135 
          Alaska   AK   West population  710231 
          Alaska   AK   West    total   19 
          Arizona  AZ   West population 6392017 
          Arizona  AZ   West      total     232         
```

```         
          state      abb Northeast South North Central West 
          Alabama     AL        NA 4779736   NA        NA 
          Alaska      AK        NA    NA     NA      710231 
          Arizona     AZ        NA    NA     NA      6392017 
          Arkansas    AR        NA 2915918   NA        NA 
          California  CA        NA    NA     NA      37253956 
          Colorado    CO        NA    NA     NA      5029196         
```

```         
          state      abb region     rate 
          Alabama     AL  South 2.82e-05 
          Alaska      AK   West 2.68e-05 
          Arizona     AZ   West 3.63e-05 
          Arkansas    AR  South 3.19e-05 
          California  CA   West 3.37e-05 
          Colorado    CO   West 1.29e-05         
```

#### Question 5

Your file called "times.csv" has age groups and average race finish times for three years of marathons.

```         
    age_group,2015,2016,2017 
    20,3:46,3:22,3:50 
    30,3:50,3:43,4:43 
    40,4:39,3:49,4:51 
    50,4:48,4:59,5:01   
```

You read in the data file using the following command.

```         
    d <- read_csv("times.csv")   
```

Which of the following commands will help you "tidy" the data?

```         
tidy_data <- d %>% 
pivot_longer('2015':'2017', names_to = "year", values_to = "time")         
```

```         
tidy_data <- d %>% 
pivot_wider('2015':'2017', names_from = year, values_from = time)         
```

```         
tidy_data <- d %>% 
pivot_longer(age_group, names_to = "year", values_to = "time")         
```

```         
tidy_data <- d %>% 
pivot_wider(age_group, names_from = year, values_from = time)
```

#### Question 6

You have a dataset on U.S. contagious diseases, but it is in the following wide format:

```         
    > head(dat_wide) 
    state year population HepatitisA Mumps Polio Rubella 
    Alabama 1990    4040587      86    19    76    1 
    Alabama 1991    4066003      39    14    65    0 
    Alabama 1992    4097169      35    12    24    0 
    Alabama 1993    4133242      40    22    67    0 
    Alabama 1994    4173361      72    12    39    0 
    Alabama 1995    4216645      75     2    38    0   
```

You want to transform this into a tidy dataset, with each row representing an observation of the incidence of each specific disease (as shown below):

```         
    > head(dat_tidy) state   year  population  disease  count Alabama 1990  4040587 HepatitisA  86 Alabama 1991 4066003 HepatitisA  39 Alabama 1992 4097169 HepatitisA  35 Alabama 1993 4133242 HepatitisA  40 Alabama 1994 4173361 HepatitisA  72 Alabama 1995 4216645 HepatitisA  75   
```

Which of the following commands would achieve this transformation to tidy the data?

Pay attention to the column names.

```         
dat_tidy <- dat_wide %>%     
pivot_longer(HepatitisA, Rubella, names_to = "disease", values_to = "count")         
```

```         
dat_tidy <- dat_wide %>%     
pivot_longer(-state, -year, -population, names_to = "disease", values_to = "count")         
```

```         
dat_tidy <- dat_wide %>%     
pivot_longer(-state, names_to = "disease", values_to = "count")         
```

```         
dat_tidy <- dat_wide %>%     
pivot_longer(HepatitisA:Rubella, names_to = "disease", values_to = "count")         
```

#### Question 7

You have successfully formatted marathon finish times into a tidy object called `tidy_data`. The first few lines are shown below.

```         
    age_group year   time 
    20        2015   03:46 
    30        2015   03:50 
    40        2015   04:39 
    50        2015   04:48 
    20        2016   03:22   
```

Select the code that converts these data back to the wide format, where each year has a separate column.

```         
tidy_data %>% 
pivot_wider(names_from = time, values_from = year)         
```

```         
tidy_data %>% 
pivot_wider(names_from = year, values_from = time)         
```

```         
tidy_data %>% 
pivot_wider(names_from = year, values_from = age_group)         
```

```         
tidy_data %>% 
pivot_wider(names_from = 2015:2017, values_from = time)         
```

#### Question 8

You have the following dataset:

```         
    > head(dat) state   abb region      var   people 
    Alabama  AL  South population 4779736 
    Alabama  AL  South      total     135 
    Alaska   AK   West population  710231 
    Alaska   AK   West      total      19 
    Arizona  AZ   West population 6392017 
    Arizona  AZ   West      total     232   
```

You would like to transform it into a dataset where population and total are each their own column (shown below):

```         
    state      abb region population total 
    Alabama     AL  South   4779736   135 
    Alaska      AK   West    710231    19 
    Arizona     AZ   West   6392017   232 
    Arkansas    AR  South   2915918    93 
    California  CA   West  37253956  1257 
    Colorado    CO   West   5029196    65   
```

Which code would best accomplish this?

```         
dat_tidy <- dat %>% 
pivot_wider(names_from = var, values_from = people)         
```

```         
dat_tidy <- dat %>% 
pivot_wider(names_from = state:region, values_from = people)         
```

```         
dat_tidy <- dat %>% 
pivot_wider(names_from = people, values_from = var)         
```

```         
dat_tidy <- dat %>% 
pivot_wider(names_from = region, values_from = people)         
```

#### Question 9

A collaborator sends you a file containing data for two years of average race finish times, "times.csv":

```         
age_group,2015_time,2015_participants,2016_time,2016_participants 
20,3:46,54,3:22,62 
30,3:50,60,3:43,58 
40,4:39,29,3:49,33 
50,4:48,10,4:59,14     
```

You read in the data file:

`d <- read_csv("times.csv", col_types="dcccc")`

Which of the answers below best makes the data tidy?

```         

tidy_data <- d %>%     
pivot_longer(-age_group, names_to = "key", values_to = "value") %>%      
separate(col = key, into = (c("year", "variable_name")), sep = ".") %>%      
pivot_wider(names_from = variable_name, values_from = value)         
```

```         

tidy_data <- d %>%     
pivot_longer(-age_group, names_to = "key", values_to = "value") %>%      
separate(col  = key, into  = (c("year", "variable_name")), sep = "_") %>%      
pivot_wider(names_from = variable_name, values_from = value)         
```

```         

tidy_data <- d %>%     pivot_longer(names_to = "key", values_to = "value") %>%      
separate(col  = key, into  = (c("year", "variable_name")), sep = "_") %>%      
pivot_wider(names_from = variable_name, values_from = value)         
```

```         

tidy_data <- d %>%     pivot_longer(-age_group, names_to = "key", values_to = "value") %>%      
separate(col = key, into = "year", sep = "_") %>%      
pivot_wider(names_from = year, values_from = value)
```

#### Question 10

You are in the process of tidying some data on heights, hand length, and wingspan for basketball players in the draft. Currently, you have the following:

```         
> head(stats) 
key               value 
allen_height      75 
allen_hand_length 8.25 
allen_wingspan    79.25 
bamba_height      83.25 
bamba_hand_length 9.75 
bamba_wingspan    94    
```

Select all of the correct commands below that would turn this data into a "tidy" format with columns "height", "hand_length" and "wingspan".

```         
tidy_data <- stats %>%     
separate(col = key, into = c("player", "variable_name"), sep = "_", extra = "merge") %>%      
pivot_wider(names_from = variable_name, values_from = value)         
```

```         
tidy_data <- stats %>%     
separate(col = key, into = c("player", "variable_name1", "variable_name2"), sep = "_", fill = "right") %>%      
unite(col = variable_name, variable_name1, variable_name2, sep = "_") %>%      
pivot_wider(names_from = variable_name, values_from = value)         
```

```         
tidy_data <- stats %>%     
separate(col = key, into = c("player", "variable_name"), sep = "_") %>%      
pivot_wider(names_from = variable_name, values_from = value)
```

### **Assessment Part 2: Reshaping Data**

#### Question 11

Examine the built-in dataset `co2`. This dataset comes with base R, not **dslabs** - just type `co2` to access the dataset.

Is `co2` tidy? Why or why not?

`co2` is tidy data: it has one year for each row.

`co2` is tidy data: each column is a different month.

`co2` is not tidy: there are multiple observations per column.

`co2` is not tidy: to be tidy we would have to wrangle it to have three columns (year, month, and value), and then each co2 observation would have a row.

#### Question 12

Run the following code to define the `co2_wide` object:

```         
co2_wide <- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) %>%      setNames(1:12) %>%     mutate(year = as.character(1959:1997))     
```

Use the `pivot_longer()` function to make this dataset tidy. Call the column with the CO2 measurements `co2` and call the month column `month`. Name the resulting object `co2_tidy`.

Which code would return the correct tidy format?

`co2_tidy <- pivot_longer(co2_wide, year, names_to = "month", values_to = "co2")`

`co2_tidy <- pivot_longer(co2_wide, -year, names_to = "co2", values_to = "month")`

`co2_tidy <- pivot_longer(co2_wide, year, names_to = "co2", values_to = "month")`

`co2_tidy <- pivot_longer(co2_wide, -year, names_to = "month", values_to = "co2")`

#### Question 13

Use `co2_tidy` to plot CO~2~ versus month with a different curve for each year:

```         
co2_tidy %>% ggplot(aes(as.numeric(month), co2, color = year)) + geom_line()     
```

What can be concluded from this plot?

CO~2~ concentrations increased monotonically (never decreased) from 1959 to 1997.

CO~2~ concentrations are highest around May and the yearly average increased from 1959 to 1997.

CO~2~ concentrations are highest around October and the yearly average increased from 1959 to 1997.

Yearly average CO~2~ concentrations have remained constant over time.

CO~2~ concentrations do not have a seasonal trend.

#### Question 14

Load the `admissions` dataset from **dslabs**, which contains college admission information for men and women across six majors, and remove the `applicants` percentage column:

```         
library(dslabs) 
data(admissions) 
dat <- admissions %>% select(-applicants)     
```

Your goal is to get the data in the shape that has one row for each major, like this:

```         
major  men   women 
A      62    82      
B      63    68      
C      37    34      
D      33    35      
E      28    24      
F       6     7      
```

Which command could help you to wrangle the data into the desired format?

`dat_tidy <- pivot_wider(dat, names_from = major, values_from = admitted)`

`dat_tidy <- pivot_wider(dat, names_from = gender, values_from = major)`

`dat_tidy <- pivot_wider(dat, names_from = gender, values_from = admitted)`

`dat_tidy <- pivot_wider(dat, names_from = admitted, values_from = major)`

#### Question 15

Now use the `admissions` dataset to create the object `tmp`, which has columns `major`, `gender`, `key` and `value`:

```         
tmp <- admissions %>%   pivot_longer(cols = c(admitted, applicants), names_to = "key", values_to = "value") tmp     
```

Combine the key and gender and create a new column called `column_name` to get a variable with the following values: `admitted_men`, `admitted_women`, `applicants_men`, and `applicants_women`. Save the new data as `tmp2`.

Which command could help you to wrangle the data into the desired format?

```         
tmp2 <- pivot_wider(tmp, names_from = column_name, values_from = key, gender)         
```

```         
tmp2 <- pivot_longer(tmp, names_to = "column_name", values_to = c("gender", "key"))         
```

```         
tmp2 <- unite(tmp, column_name, c(gender, key))         
```

```         
tmp2 <- pivot_wider(tmp, names_from = column_name, values_from = c(key, gender))         
```

```         
tmp2 <- unite(tmp, column_name, c(key, gender))         
```

#### Question 16

Which function can reshape `tmp2` to a table with six rows and five columns named `major`, `admitted_men`, `admitted_women`, `applicants_men`, and `applicants_women`?

`pivot_longer()`

`pivot_wider()`

`separate()`

`unite()`

## 2.2: **Combining Tables**

### **Combining Tables**

**Key points**

-   The `join` functions in the **dplyr** package combine two tables such that matching rows are together.

-   `left_join()` only keeps rows that have information in the first table.

-   `right_join()` only keeps rows that have information in the second table.

-   `inner_join()` only keeps rows that have information in both tables.

-   `full_join()` keeps all rows from both tables.

-   `semi_join()` keeps the part of first table for which we have information in the second.

-   `anti_join()` keeps the elements of the first table for which there is no information in the second.

**Code**

```{r}
# import US murders data
library(tidyverse)
library(ggrepel)
library(dslabs)
ds_theme_set()
data(murders)
head(murders)

# import US election results data
data(polls_us_election_2016)
head(results_us_election_2016)
identical(results_us_election_2016$state, murders$state)

# join the murders table and US election results table
tab <- left_join(murders, results_us_election_2016, by = "state")
head(tab)

# plot electoral votes versus population
tab %>% ggplot(aes(population/10^6, electoral_votes, label = abb)) +
  geom_point() +
  geom_text_repel() + 
  scale_x_continuous(trans = "log2") +
  scale_y_continuous(trans = "log2") +
  geom_smooth(method = "lm", se = FALSE)

# make two smaller tables to demonstrate joins
tab1 <- slice(murders, 1:6) %>% select(state, population)
tab1
tab2 <- slice(results_us_election_2016, c(1:3, 5, 7:8)) %>% select(state, electoral_votes)
tab2

# experiment with different joins
left_join(tab1, tab2)
tab1 %>% left_join(tab2)
tab1 %>% right_join(tab2)
inner_join(tab1, tab2)
semi_join(tab1, tab2)
anti_join(tab1, tab2)
```

### **Binding**

**Key points**

-   Unlike the join functions, the binding functions do not try to match by a variable, but rather just combine datasets.

-   `bind_cols()` binds two objects by making them columns in a tibble. The R-base function `cbind()` binds columns but makes a data frame or matrix instead.

-   The `bind_rows()` function is similar but binds rows instead of columns. The R-base function `rbind()` binds rows but makes a data frame or matrix instead.

**Code**

```{r}
bind_cols(a = 1:3, b = 4:6)

tab1 <- tab[, 1:3]
tab2 <- tab[, 4:6]
tab3 <- tab[, 7:9]
new_tab <- bind_cols(tab1, tab2, tab3)
head(new_tab)

tab1 <- tab[1:2,]
tab2 <- tab[3:4,]
bind_rows(tab1, tab2)
```

### **Set Operators**

**Key points**

-   By default, the set operators in R-base work on vectors. If **tidyverse/dplyr** are loaded, they also work on data frames.

-   You can take intersections of vectors using `intersect()`. This returns the elements common to both sets.

-   You can take the union of vectors using `union()`. This returns the elements that are in either set.

-   The set difference between a first and second argument can be obtained with `setdiff()`. Note that this function is not symmetric.

-   The function `set_equal()` tells us if two sets are the same, regardless of the order of elements.

**Code**

```{r}
# intersect vectors or data frames
intersect(1:10, 6:15)
intersect(c("a","b","c"), c("b","c","d"))
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
intersect(tab1, tab2)

# perform a union of vectors or data frames
union(1:10, 6:15)
union(c("a","b","c"), c("b","c","d"))
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
union(tab1, tab2)

# set difference of vectors or data frames
setdiff(1:10, 6:15)
setdiff(6:15, 1:10)
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
setdiff(tab1, tab2)

# setequal determines whether sets have the same elements, regardless of order
setequal(1:5, 1:6)
setequal(1:5, 5:1)
setequal(tab1, tab2)
```

### **Assessment: Combining Tables**

#### Question 1

You have created data frames `tab1` and `tab2` of state population and election data, similar to our module videos:

```         
> tab1 
state            population 
Alabama             4779736 
Alaska               710231 
Arizona             6392017 
Delaware             897934 
District of Columbia 601723  

> tab2 
state  electoral_votes 
Alabama      9 
Alaska       3 
Arizona     11 
California  55 
Colorado     9 
Connecticut  7  

> dim(tab1) 
[1] 5 2  

> dim(tab2) 
[1] 6 2     
```

What are the dimensions of the table `dat`, created by the following command?

```         
dat <- left_join(tab1, tab2, by = “state”)     
```

3 rows by 3 columns

5 rows by 2 columns

5 rows by 3 columns

6 rows by 3 columns

#### Question 2

We are still using the `tab1` and `tab2` tables shown in question 1. What join command would create a new table "dat" with three rows and two columns?

```         
dat <- right_join(tab1, tab2, by = “state”)         
```

```         
dat <- full_join(tab1, tab2, by = “state”)          
```

```         
dat <- inner_join(tab1, tab2, by = “state”)          
```

```         
dat <- semi_join(tab1, tab2, by = “state”)          
```

#### Question 3

Which of the following are real differences between the join and bind functions?

Select ALL that apply.

Binding functions combine by position, while join functions match by variables.

Joining functions can join datasets of different dimensions, but the bind functions must match on the appropriate dimension (either same row or column numbers).

Bind functions can combine both vectors and dataframes, while join functions work for only for dataframes.

The join functions are a part of the dplyr package and have been optimized for speed, while the bind functions are inefficient base functions.

#### Question 4

We have two simple tables, shown below, with columns `x` and `y`:

```         
> df1  
x     y      
a     a      
b     a     

> df2  
x     y      
a     a      
a     b       
```

Which command would result in the following table?

```         
> final  
x     y      
b     a        
```

```         
final <- union(df1, df2)         
```

```         
final <- setdiff(df1, df2)         
```

```         
final <- setdiff(df2, df1)         
```

```         
final <- intersect(df1, df2)         
```

#### Introduction to Questions 5-7

Install and load the **Lahman** library. This library contains a variety of datasets related to US professional baseball. We will use this library for the next few questions and will discuss it more extensively in the Regression course. For now, focus on wrangling the data rather than understanding the statistics.

The `Batting` data frame contains the offensive statistics for all baseball players over several seasons.  Filter this data frame to define `top` as the top 10 home run (`HR`) hitters in 2016:

```{r}
library(Lahman) 
top <- Batting %>%    
  filter(yearID == 2016) %>%   
  arrange(desc(HR)) %>%    # arrange by descending HR count   
  slice(1:10)    # take entries 1-10 
top %>% as_tibble()
```

Also Inspect the `People` data frame, which has demographic information for all players:

```{r}
People %>% as_tibble()
```

#### Question 5

Use the correct `join` or `bind` function to create a combined table of the names and statistics of the top 10 home run (HR) hitters for 2016. This table should have the player ID, first name, last name, and number of HR for the top 10 players. Name this data frame `top_names`.

Identify the `join` or `bind` that fills the blank in this code to create the correct table:

```         
top_names <- top %>% ___________________ %>%     
select(playerID, nameFirst, nameLast, HR)     
```

Which bind or join function fills the blank to generate the correct table?

`rbind(People)`

`cbind(People)`

`left_join(People)`

`right_join(People)`

`full_join(People)`

`anti_join(People)`

```{r}
top_names <- top %>% left_join(People) %>%     
select(playerID, nameFirst, nameLast, HR)    
```

#### Question 6

Inspect the `Salaries` data frame. Filter this data frame to the 2016 salaries, then use the correct bind join function to add a `salary` column to the `top_names` data frame from the previous question. Name the new data frame `top_salary`. Use this code framework:

```         
top_salary <- Salaries %>% filter(yearID == 2016) %>%   
______________ %>%   
select(nameFirst, nameLast, teamID, HR, salary)     
```

Which bind or join function fills the blank to generate the correct table?

`rbind(top_names)`

`cbind(top_names)`

`left_join(top_names)`

`right_join(top_names)`

`full_join(top_names)`

`anti_join(top_names)`

```{r}
top_salary <- Salaries %>% filter(yearID==2016) %>%
  right_join(top_names) %>%
  select(nameFirst, nameLast, teamID, HR, salary)
top_salary   
```

#### Question 7

Inspect the `AwardsPlayers` table. Filter awards to include only the year 2016.

How many players from the top 10 home run hitters won at least one award in 2016?

Use a set operator.

\[ \]

```{r}
# Filter AwardsPlayers for the year 2016
awards_2016 <- AwardsPlayers %>% filter(yearID == 2016)

# Extract unique player IDs from the top_names data frame
playerIDs_top_names <- unique(top_names$playerID)

# Use the intersect set operator to find common player IDs
players_with_awards <- intersect(playerIDs_top_names, awards_2016$playerID)

# Calculate the number of players with at least one award in 2016
num_players_with_awards <- length(players_with_awards)

# Print the result
print(num_players_with_awards)
```

How many players won an award in 2016 but were not one of the top 10 home run hitters in 2016?

Use a set operator.

\[ \]

```{r}
# Filter AwardsPlayers for the year 2016
awards_2016 <- AwardsPlayers %>% filter(yearID == 2016)

# Extract unique player IDs from the top_names and awards_2016 data frames
playerIDs_top_names <- unique(top_names$playerID)
playerIDs_awards_2016 <- unique(awards_2016$playerID)

# Use setdiff to find player IDs who won an award but were not in the top 10 home run hitters
players_with_awards_not_top_10 <- setdiff(playerIDs_awards_2016, playerIDs_top_names)

# Calculate the number of players with awards but not in the top 10 home run hitters
num_players_with_awards_not_top_10 <- length(players_with_awards_not_top_10)

# Print the result
print(num_players_with_awards_not_top_10)

```

#### Question 8

What must be true for functions such as `intersect()`, `union()`, and `setDiff()` to work on a data frame?

Select ALL that apply.

The data frames must have the same number of columns.

The columns in both data frames must have identical names.

The data frames must have the same number of rows.

## 2.3: **Web Scraping**

**Key points**

-   Web scraping is extracting data from a website.

-   The **rvest** web harvesting package includes functions to extract nodes of an HTML document: `html_nodes()` extracts all nodes of different types, and `html_node()` extracts the first node.

-   `html_table()` converts an HTML table to a data frame.

**Code**

```{r}
# import a webpage into R
library(rvest)
url <- "https://en.wikipedia.org/wiki/Murder_in_the_United_States_by_state"
h <- read_html(url)
class(h)
h

tab <- h %>% html_nodes("table")
tab <- tab[[3]]

tab <- tab %>% html_table
class(tab)

tab <- tab %>% setNames(c("state", "population", "total", "murders", "gun_murders", "gun_ownership", "total_rate", "murder_rate", "gun_murder_rate"))
head(tab)
```

### **CSS Selectors**

The default look of webpages made with the most basic HTML is quite unattractive. The aesthetically pleasing pages we see today are made using CSS. CSS is used to add style to webpages. The fact that all pages for a company have the same style is usually a result that they all use the same CSS file. The general way these CSS files work is by defining how each of the elements of a webpage will look. The title, headings, itemized lists, tables, and links, for example, each receive their own style including font, color, size, and distance from the margin, among others.

To do this CSS leverages patterns used to define these elements, referred to as *selectors*. An example of pattern we used in a previous video is `table` but there are many many more. If we want to grab data from a webpage and we happen to know a selector that is unique to the part of the page, we can use the `html_nodes()` function.

However, knowing which selector to use can be quite complicated. To demonstrate this we will try to extract the recipe name, total preparation time, and list of ingredients from [this guacamole recipe External link](http://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609). Looking at the code for this page, it seems that the task is impossibly complex. However, selector gadgets actually make this possible. [SelectorGadget External link](http://selectorgadget.com/) is piece of software that allows you to interactively determine what CSS selector you need to extract specific components from the webpage. If you plan on scraping data other than tables, we highly recommend you install it. A Chrome extension is available which permits you to turn on the gadget highlighting parts of the page as you click through, showing the necessary selector to extract those segments.

For the guacamole recipe page, we already have done this and determined that we need the following selectors:

```{r}
h <- read_html("http://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609")
recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()
```

You can see how complex the selectors are. In any case we are now ready to extract what we want and create a list:

```{r}
guacamole <- list(recipe, prep_time, ingredients)
guacamole
```

Since recipe pages from this website follow this general layout, we can use this code to create a function that extracts this information:

```{r}
get_recipe <- function(url){
    h <- read_html(url)
    recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
    prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
    ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()
    return(list(recipe = recipe, prep_time = prep_time, ingredients = ingredients))
} 
```

and then use it on any of their webpages:

```{r}
get_recipe("http://www.foodnetwork.com/recipes/food-network-kitchen/pancakes-recipe-1913844")

```

There are several other powerful tools provided by **rvest**. For example, the functions `html_form()`, `set_values()`, and `submit_form()` permit you to query a webpage from R. This is a more advanced topic not covered here.

### **Assessment: Web Scraping**

### Introduction: Questions 1-3

Load the following web page, which contains information about Major League Baseball payrolls, into R: [https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm External link](https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm)

```{r}
library(rvest) 
url <- "https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm" 
h <- read_html(url)
```

We learned that tables in html are associated with the `table` node.  Use the `html_nodes()` function and the `table` node type to extract the first table. Store it in an object `nodes`:

```{r}
nodes <- html_nodes(h, "table")
```

The `html_nodes()` function returns a list of objects of class `xml_node`. We can see the content of each one using, for example, the `html_text()` function. You can see the content for an arbitrarily picked component like this:

```{r}
html_text(nodes[[8]])
```

If the content of this object is an html table, we can use the `html_table()` function to convert it to a data frame:

```{r}
html_table(nodes[[8]])
```

You will analyze the tables from this HTML page over questions 1-3.

#### Question 1

Many tables on this page are team payroll or salary information tables - with columns for rank, team, and one or more money values.

Convert the first four tables in `nodes` to data frames and inspect them.

***Note that "parsing errors" and/or "empty tables" still count towards the table index!***

Which of the first four `nodes` are tables of team payroll?

Check all correct answers. Look at table content, not column names.

*Remember that payroll is information about the total salary on a team.*

Table 1

Table 2

Table 3

Table 4

None of the above

```{r}

html_table(nodes[[length(nodes)-2]])
html_table(nodes[[length(nodes)-1]])
html_table(nodes[[length(nodes)]])

```

#### Question 2

For the last 3 components of `nodes`, which of the following are true? (Check all correct answers.)

Check all correct answers.

All three entries are tables.

All three entries are tables of payroll per team.

The last entry shows the average across all teams through time, not payroll per team.

None of the three entries are tables of payroll per team.

#### Question 3

Create a table called `tab_1` using entry 10 of `nodes`. Create a table called `tab_2` using entry 19 of `nodes`.

Note that the column names should be `c("Team", "Payroll", "Average")`. You can see that these column names are actually in the first data row of each table, and that `tab_1` has an extra first column `No.` that should be removed so that the column names for both tables match.

Remove the extra column in `tab_1`, remove the first row of each dataset, and change the column names for each table to `c("Team", "Payroll", "Average")`. Use a `full_join()` by the `Team` to combine these two tables.

How many rows are in the joined data table?

\[ \]

```{r}
tab_1 <- html_table(nodes[10])
tab_1 <- as.data.frame(tab_1)
tab_1 <- tab_1[-1, -1]
tab_2 <- html_table(nodes[19])
tab_2 <- as.data.frame(tab_2)
tab_2 <- tab_2[-1,]
names(tab_1) <- c("Team", "Payroll", "Average")
names(tab_2) <- c("Team", "Payroll", "Average")
full_join(tab_1,tab_2, by = "Team") %>% 
  nrow()
```

#### Introduction: Questions 4 and 5

The Wikipedia page on [opinion polling for the Brexit referendum External link](https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054), in which the United Kingdom voted to leave the European Union in June 2016, contains several tables. One table contains the results of all polls regarding the referendum over 2016:

![](https://courses.edx.org/assets/courseware/v1/09143c127abef79db9a5c18bc6b06d5e/asset-v1:HarvardX+PH125.6x+1T2023+type@asset+block/brexit-wiki-table.png)

Use the **rvest** library to read the HTML from this Wikipedia page (make sure to copy both lines of the URL):

```{r}
library(rvest)
library(tidyverse)
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"
```

#### Question 4

#### Assign `tab` to be the html nodes of the "table" class.

How many tables are in this Wikipedia page?

\[ \]

```{r}
new_target <- read_html(url)
tab <- html_nodes(new_target, "table")
length(tab)

```

### Question 5

Inspect the first several html tables using `html_table()` with the argument `fill=TRUE` (you can read about this argument in the documentation). Find the first table that has 9 columns with the first column named "Date(s) conducted".

What is the first table number to have 9 columns where the first column is named "Date(s) conducted"?

\[ \]

```{r}
tab[[1]] %>% html_table(fill = TRUE) %>% names()  
tab[[2]] %>% html_table(fill = TRUE) %>% names()  
tab[[3]] %>% html_table(fill = TRUE) %>% names()  
tab[[4]] %>% html_table(fill = TRUE) %>% names()  
tab[[5]] %>% html_table(fill = TRUE) %>% names()  
tab[[6]] %>% html_table(fill = TRUE) %>% names()  

```
